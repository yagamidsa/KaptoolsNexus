# backend/mdd_real_service.py - ARCHIVO COMPLETO BASADO EN TU C√ìDIGO ORIGINAL PYTHON
# DUPLICACI√ìN REAL USANDO DMSRUN - LECTURA EXACTA DEL OUTPUT COMO EN TU C√ìDIGO

import os
import subprocess
import tempfile
import shutil
import logging
import glob
import re
import zipfile
from datetime import datetime
from typing import Dict, List, Any, Optional
import concurrent.futures
from pathlib import Path

logger = logging.getLogger(__name__)

class IBMSPSSDataCollectionService:
    """Servicio basado EXACTAMENTE en tu c√≥digo Python original"""
    
    def __init__(self):
        self.service_name = "MDD Exact Like Original Python"
        self.version = "4.3-ORIGINAL_PYTHON_METHOD"
        self.dms_command = "dmsrun"
        self.current_workspace = None
        self.original_mdd_path = None
        self.original_ddf_path = None
        logger.info("‚úÖ MDD Service initialized EXACTLY like your original Python code")
        logger.info(f"üîß Using DMS command: {self.dms_command}")
    
    def get_service_status(self) -> Dict[str, Any]:
        """Estado del servicio basado en tu c√≥digo"""
        return {
            "service_name": self.service_name,
            "version": self.version,
            "mode": "ORIGINAL_PYTHON_METHOD",
            "max_duplicates": 50,
            "uses_original_method": True,
            "dms_command": self.dms_command,
            "features": ["original_python_logic", "dms_stdout_parsing", "exact_like_qt_version"],
            "status": "active"
        }
    
    async def process_duplicate_mdd_real(
        self, 
        mdd_file_path: str, 
        ddf_file_path: str, 
        duplicate_count: int, 
        workspace_path: str, 
        original_mdd_filename: str
    ) -> Dict[str, Any]:
        """Proceso EXACTAMENTE como tu c√≥digo Python original"""
        
        logger.info(f"üöÄ Starting MDD duplication EXACTLY like your original Python code")
        start_time = datetime.now()
        logs = []
        
        def add_log(message: str):
            timestamp = datetime.now().strftime("%H:%M:%S")
            log_entry = f"[{timestamp}] {message}"
            logs.append(log_entry)
            logger.info(message)
        
        # üî• GUARDAR DATOS COMO EN TU C√ìDIGO ORIGINAL
        self.current_workspace = workspace_path
        self.original_mdd_path = mdd_file_path
        self.original_ddf_path = ddf_file_path
        add_log(f"üìÅ Files saved for processing like original Python code")
        add_log(f"üìã MDD: {os.path.basename(mdd_file_path)}")
        add_log(f"üíæ DDF: {os.path.basename(ddf_file_path)}")
        
        try:
            # Preparaci√≥n EXACTAMENTE como tu c√≥digo
            add_log("üîç Starting process exactly like original Python code...")
            
            # Variables como en tu c√≥digo original
            strInputMdd = os.path.splitext(os.path.basename(original_mdd_filename))[0]
            count = duplicate_count
            strInputMdd = os.path.join(workspace_path, strInputMdd)
            CASEDATA_OUT = strInputMdd + "_Completes_All.ddf"
            METADATA_OUT = strInputMdd + "_Completes_All.mdd"
            
            add_log(f"üìã strInputMdd: {strInputMdd}")
            add_log(f"üìÅ CASEDATA_OUT: {CASEDATA_OUT}")
            add_log(f"üìÅ METADATA_OUT: {METADATA_OUT}")
            
            # Limpiar archivos existentes COMO EN TU C√ìDIGO
            if os.path.exists(CASEDATA_OUT) and os.path.exists(METADATA_OUT):
                os.remove(CASEDATA_OUT)
                os.remove(METADATA_OUT)
                add_log("üßπ Cleaned existing output files")
            
            # PASO 1: Crear copias y script DMS EXACTAMENTE como tu c√≥digo
            add_log(f"üìã Creating {count} file copies and DMS script...")
            dms_output = await self._execute_original_python_method(
                strInputMdd, count, CASEDATA_OUT, METADATA_OUT, workspace_path, add_log
            )
            
            # PASO 2: Limpiar archivos temporales COMO EN TU C√ìDIGO
            add_log("üßπ Cleaning temporary files...")
            self._cleanup_temp_files_original_method(workspace_path, add_log)
            
            # PASO 3: Crear estructura ZIP COMO EN TU C√ìDIGO
            add_log("üì¶ Creating ZIP structure like original code...")
            zip_path = await self._create_zip_structure_original_method(
                workspace_path, strInputMdd, CASEDATA_OUT, METADATA_OUT, add_log
            )
            
            # PASO 4: Limpiar archivos finales COMO EN TU C√ìDIGO
            if os.path.exists(CASEDATA_OUT) and os.path.exists(METADATA_OUT):
                os.remove(CASEDATA_OUT)
                os.remove(METADATA_OUT)
                add_log("üßπ Cleaned final output files")
            
            processing_time = (datetime.now() - start_time).total_seconds()
            
            # üî• LEER RECORDS EXACTAMENTE COMO EN TU C√ìDIGO ORIGINAL
            add_log("üìä Reading record counts EXACTLY like original Python code...")
            original_records, final_records = self._extract_records_from_dms_output(dms_output, duplicate_count)
            
            add_log(f"‚úÖ Duplication completed in {processing_time:.1f}s")
            add_log(f"üìä Records like original: {original_records} ‚Üí {final_records} (√ó{duplicate_count})")
            
            return {
                "success": True,
                "message": "‚úÖ MDD duplication completed EXACTLY like original Python code!",
                "output_file": os.path.basename(zip_path),
                "output_path": zip_path,
                "duplicates_created": duplicate_count,
                "base_name": os.path.splitext(os.path.basename(original_mdd_filename))[0],
                "file_size": os.path.getsize(zip_path),
                "original_records": original_records,
                "total_records": final_records,
                "record_multiplier": duplicate_count,
                "processing_time_seconds": int(processing_time),
                "logs": logs,
                "mode": "ORIGINAL_PYTHON_METHOD",
                "dms_output": dms_output,
                "method": "Exact replication of your original Python code",
                "optimizations_applied": [
                    "Original Python logic preserved",
                    "DMS stdout parsing like original",
                    "File operations like original",
                    "ZIP structure like original"
                ]
            }
            
        except Exception as e:
            add_log(f"‚ùå Error: {str(e)}")
            logger.error(f"Duplication failed: {str(e)}")
            
            return {
                "success": False,
                "error": str(e),
                "logs": logs,
                "mode": "ORIGINAL_METHOD_ERROR"
            }
    
    async def _execute_original_python_method(self, strInputMdd, count, CASEDATA_OUT, METADATA_OUT, workspace_path, add_log):
        """EJECUTA EXACTAMENTE como en tu c√≥digo Python original"""
        
        try:
            # Crear archivo temp.dms EXACTAMENTE como en tu c√≥digo
            temp_dms_path = os.path.join(workspace_path, "temp.dms")
            
            with open(temp_dms_path, "w") as objFile:
                # Crear copias de archivos EXACTAMENTE como en tu c√≥digo
                for i in range(1, count + 1):
                    # Copiar archivos como en tu c√≥digo original
                    mdd_copy = strInputMdd + "_" + str(i) + ".mdd"
                    ddf_copy = strInputMdd + "_" + str(i) + ".ddf"
                    
                    shutil.copyfile(self.original_mdd_path, mdd_copy)
                    shutil.copyfile(self.original_ddf_path, ddf_copy)
                    
                    add_log(f"üìã Copied files for Input{i}")
                    
                    # Escribir DMS script EXACTAMENTE como en tu c√≥digo
                    objFile.write("InputDataSource(Input" + str(i) + ")\n")
                    objFile.write(
                        '    ConnectionString="Provider=mrOleDB.Provider.2;Data Source=mrDataFileDsc;Initial Catalog='
                        + strInputMdd + "_" + str(i) + ".mdd;Location=" + strInputMdd + "_" + str(i) + '.ddf"\n'
                    )
                    objFile.write('    SelectQuery = "SELECT * FROM VDATA"\n')
                    objFile.write("End InputDataSource\n\n")
                
                # Output data source EXACTAMENTE como en tu c√≥digo
                objFile.write("OutputDataSource(Out)\n")
                objFile.write(
                    '    ConnectionString="Provider=mrOleDB.Provider.2;Data Source=mrDataFileDsc;Location='
                    + CASEDATA_OUT + '"\n'
                )
                objFile.write('    MetaDataOutputName = "' + METADATA_OUT + '"\n')
                objFile.write("End OutputDataSource\n\n")
                
                # Event EXACTAMENTE como en tu c√≥digo
                objFile.write('Event(OnNextCase, "Populate derived variables")\n')
                objFile.write(
                    "    Respondent.serial = (clong(dmgrjob.CurrentInputDataSource) * 1000) + Respondent.serial\n"
                )
                objFile.write("End Event\n")
            
            add_log("üìú Created temp.dms script exactly like original code")
            
            # Ejecutar dmsrun EXACTAMENTE como en tu c√≥digo original
            add_log("‚ö° Executing dmsrun exactly like original Python code...")
            
            result = subprocess.run(
                ["dmsrun", "temp.dms"], 
                cwd=workspace_path,
                capture_output=True, 
                text=True,
                timeout=600,
                encoding='utf-8',
                errors='ignore'
            )
            
            # Capturar output EXACTAMENTE como en tu c√≥digo: output = result.stdout
            output = result.stdout
            
            add_log(f"üìù DMS execution completed. Output length: {len(output)} chars")
            add_log(f"üìù Return code: {result.returncode}")
            
            # Log del output para debugging (primeros 500 chars)
            if output:
                add_log(f"üìÑ DMS Output preview: {output[:500]}...")
            
            if result.stderr:
                add_log(f"‚ö†Ô∏è DMS Stderr: {result.stderr[:200]}...")
            
            # Limpiar temp.dms EXACTAMENTE como en tu c√≥digo
            os.remove(temp_dms_path)
            add_log("üßπ Removed temp.dms")
            
            # Verificar que se crearon los archivos de salida
            if os.path.exists(CASEDATA_OUT) and os.path.exists(METADATA_OUT):
                add_log("‚úÖ Output files created successfully")
            else:
                add_log("‚ö†Ô∏è Output files not found, but continuing...")
            
            return output
            
        except Exception as e:
            add_log(f"‚ùå Error in original Python method: {str(e)}")
            raise Exception(f"Original method execution failed: {str(e)}")
    
    def _cleanup_temp_files_original_method(self, workspace_path, add_log):
        """Limpia archivos temporales EXACTAMENTE como en tu c√≥digo original"""
        
        try:
            # Patr√≥n EXACTAMENTE como en tu c√≥digo: r".+_\d+\.(mdd|ddf)$"
            pattern = r".+_\d+\.(mdd|ddf)$"
            
            files_found = []
            for raiz, directorys, files in os.walk(workspace_path):
                for file in files:
                    if re.match(pattern, file):
                        path_file = os.path.join(raiz, file)
                        files_found.append(path_file)
            
            # Eliminar archivos EXACTAMENTE como en tu c√≥digo
            for file in files_found:
                os.remove(file)
            
            add_log(f"üßπ Removed {len(files_found)} temporary files like original code")
            
        except Exception as e:
            add_log(f"‚ö†Ô∏è Error cleaning temp files: {str(e)}")
    
    async def _create_zip_structure_original_method(self, workspace_path, strInputMdd, CASEDATA_OUT, METADATA_OUT, add_log):
        """Crear ZIP EXACTAMENTE como en tu c√≥digo original"""
        
        try:
            # Variables EXACTAMENTE como en tu c√≥digo
            directory = workspace_path
            name_file = "*_Completes_All.mdd"
            destination_path = directory + "/mdd"
            
            # Crear directorio mdd EXACTAMENTE como en tu c√≥digo
            if os.path.exists(destination_path):
                shutil.rmtree(destination_path)
            
            if not os.path.exists(destination_path):
                os.makedirs(destination_path)
            
            # Buscar archivo MDD EXACTAMENTE como en tu c√≥digo
            path_file_origen = None
            for path_file in glob.glob(os.path.join(directory, name_file)):
                path_file_origen = path_file
                break
            
            if path_file_origen:
                # Copiar y renombrar EXACTAMENTE como en tu c√≥digo
                shutil.copy2(path_file_origen, destination_path)
                result_name = os.path.join(
                    destination_path,
                    os.path.splitext(os.path.basename(path_file_origen))[0].replace(
                        "_Completes_All", ".mdd"
                    ),
                )
                os.rename(
                    os.path.join(destination_path, os.path.basename(path_file_origen)),
                    result_name,
                )
                add_log(f"üìã Processed MDD file like original code")
            else:
                raise Exception("MDD file not found")
            
            # Crear directorio export EXACTAMENTE como en tu c√≥digo
            directory_destination = directory + "/export"
            
            if os.path.exists(directory_destination):
                shutil.rmtree(directory_destination)
            
            if not os.path.exists(directory_destination):
                os.makedirs(directory_destination)
            
            # Copiar archivos a export EXACTAMENTE como en tu c√≥digo
            pattern_mdd = "*_Completes_All.mdd"
            pattern_ddf = "*_Completes_All.ddf"
            
            files_mdd = glob.glob(os.path.join(directory, pattern_mdd))
            files_ddf = glob.glob(os.path.join(directory, pattern_ddf))
            
            for file in files_mdd + files_ddf:
                shutil.copy2(file, directory_destination)
                add_log(f"üì¶ Copied file: {os.path.basename(file)}")
            
            # Crear ZIP EXACTAMENTE como en tu c√≥digo
            directory_mdd = os.path.join(directory, "mdd")
            directory_export = os.path.join(directory, "export")
            
            if os.path.exists(directory_mdd) and os.path.exists(directory_export):
                # Nombre del ZIP EXACTAMENTE como en tu c√≥digo original
                base_name = os.path.splitext(os.path.basename(path_file_origen))[0]
                name_file = base_name.replace("_Completes_All", "_Completes_All.zip")
                
                path_file_zip = os.path.join(directory, name_file)
                
                with zipfile.ZipFile(path_file_zip, "w") as file_zip:
                    # Agregar archivos mdd EXACTAMENTE como en tu c√≥digo
                    for path_directory, _, files in os.walk(directory_mdd):
                        for file in files:
                            path_complete = os.path.join(path_directory, file)
                            file_zip.write(
                                path_complete,
                                arcname=os.path.join(
                                    "mdd", os.path.relpath(path_complete, directory_mdd)
                                ),
                            )
                    
                    # Agregar archivos export EXACTAMENTE como en tu c√≥digo
                    for path_directory, _, files in os.walk(directory_export):
                        for file in files:
                            path_complete = os.path.join(path_directory, file)
                            file_zip.write(
                                path_complete,
                                arcname=os.path.join(
                                    "export", os.path.relpath(path_complete, directory_export)
                                ),
                            )
                
                add_log(f"‚úÖ Created ZIP: {name_file}")
                
                # Limpiar directorios EXACTAMENTE como en tu c√≥digo
                if os.path.exists(destination_path):
                    shutil.rmtree(destination_path)
                
                if os.path.exists(directory_destination):
                    shutil.rmtree(directory_destination)
                
                return path_file_zip
            
            else:
                raise Exception("Directories 'mdd' and 'export' do not exist")
                
        except Exception as e:
            add_log(f"‚ùå Error creating ZIP: {str(e)}")
            raise Exception(f"ZIP creation failed: {str(e)}")
    
    def _extract_records_from_dms_output(self, dms_output: str, duplicate_count: int) -> tuple:
        """üî• LEE EL OUTPUT DEL DMS EXACTAMENTE COMO EN TU C√ìDIGO ORIGINAL"""
        try:
            logger.info("üéØ Reading DMS output EXACTLY like your original Python code...")
            logger.info(f"üìù DMS Output Content ({len(dms_output)} chars):")
            logger.info(f"üìù Full DMS Output: {repr(dms_output)}")
            
            # üéØ M√âTODO 1: Buscar patrones en el output del DMS (como tu c√≥digo original)
            original_records, total_records = self._parse_dms_output_like_original(dms_output, duplicate_count)
            
            if original_records > 0 and total_records > 0:
                logger.info(f"‚úÖ FROM DMS OUTPUT: Original={original_records}, Total={total_records}")
                return original_records, total_records
            
            # üéØ M√âTODO 2: Contar archivos directamente (backup)
            logger.warning("‚ö†Ô∏è No clear numbers in DMS output, counting files directly...")
            return self._count_files_like_original(duplicate_count)
            
        except Exception as e:
            logger.error(f"üí• Error reading DMS output: {e}")
            # Como √∫ltimo recurso, contar archivos
            return self._count_files_like_original(duplicate_count)
    
    def _parse_dms_output_like_original(self, dms_output: str, duplicate_count: int) -> tuple:
        """üéØ Analiza el output del DMS exactamente como en tu c√≥digo original"""
        import re
        
        # Patrones que t√≠picamente aparecen en el output de dmsrun
        patterns_to_find = [
            # Patrones m√°s comunes en DMS output
            r'(\d+)\s+record[s]?\s+processed',
            r'(\d+)\s+case[s]?\s+processed', 
            r'(\d+)\s+record[s]?\s+read',
            r'(\d+)\s+case[s]?\s+read',
            r'(\d+)\s+record[s]?\s+written',
            r'(\d+)\s+case[s]?\s+written',
            r'(\d+)\s+record[s]?\s+output',
            r'(\d+)\s+case[s]?\s+output',
            
            # Patrones para totales
            r'Total:\s*(\d+)',
            r'Total\s+records?:\s*(\d+)',
            r'Total\s+cases?:\s*(\d+)',
            
            # Patrones de progreso
            r'Processing\s+(\d+)',
            r'Completed\s+(\d+)',
            
            # N√∫meros que aparecen solos (posiblemente conteos)
            r'\b(\d+)\s+records?\b',
            r'\b(\d+)\s+cases?\b',
            
            # Buscar cualquier n√∫mero que parezca un conteo realista
            r'\b(\d{1,6})\b'  # N√∫meros de 1 a 6 d√≠gitos
        ]
        
        found_numbers = []
        
        # Buscar todos los patrones
        for pattern in patterns_to_find:
            matches = re.findall(pattern, dms_output, re.IGNORECASE)
            for match in matches:
                try:
                    number = int(match)
                    # Filtrar n√∫meros que parezcan conteos realistas
                    if 1 <= number <= 100000:  # Rango realista
                        found_numbers.append(number)
                        logger.info(f"üîç Found number in DMS output: {number}")
                except ValueError:
                    continue
        
        if found_numbers:
            # Remover duplicados y ordenar
            unique_numbers = sorted(list(set(found_numbers)))
            logger.info(f"üìä All unique numbers found: {unique_numbers}")
            
            # L√≥gica para determinar cu√°l es el total final
            if len(unique_numbers) == 1:
                # Solo un n√∫mero encontrado
                total_records = unique_numbers[0]
            else:
                # M√∫ltiples n√∫meros - buscar el que sea m√∫ltiplo de duplicate_count
                multiples = [n for n in unique_numbers if n % duplicate_count == 0]
                if multiples:
                    total_records = max(multiples)  # El m√∫ltiplo m√°s grande
                else:
                    total_records = max(unique_numbers)  # El n√∫mero m√°s grande
            
            # Calcular registros originales
            original_records = total_records // duplicate_count if duplicate_count > 0 else total_records
            
            # Verificar que la matem√°tica tenga sentido
            if total_records == original_records * duplicate_count:
                logger.info(f"‚úÖ Math check passed: {original_records} √ó {duplicate_count} = {total_records}")
                return original_records, total_records
            else:
                logger.warning(f"‚ö†Ô∏è Math doesn't match exactly: {original_records} √ó {duplicate_count} ‚â† {total_records}")
                return original_records, total_records
        
        logger.warning("‚ö†Ô∏è No valid numbers found in DMS output")
        return 0, 0
    
    def _count_files_like_original(self, duplicate_count: int) -> tuple:
        """üéØ Cuenta archivos exactamente como en tu c√≥digo original"""
        try:
            if not hasattr(self, 'current_workspace'):
                raise Exception("No workspace available")
            
            # Buscar archivos _Completes_All.ddf como en tu c√≥digo
            pattern_ddf = "*_Completes_All.ddf"
            files_ddf = glob.glob(os.path.join(self.current_workspace, pattern_ddf))
            
            if not files_ddf:
                logger.error("‚ùå No _Completes_All.ddf files found")
                raise Exception("No output DDF files found")
            
            ddf_file = files_ddf[0]
            logger.info(f"üìÅ Counting records in: {os.path.basename(ddf_file)}")
            
            # Contar l√≠neas como lo har√≠as en Python original
            total_records = 0
            with open(ddf_file, 'r', encoding='utf-8', errors='ignore') as f:
                for line in f:
                    if line.strip():  # Solo l√≠neas no vac√≠as
                        total_records += 1
            
            # Calcular registros originales
            original_records = total_records // duplicate_count if duplicate_count > 0 else total_records
            
            logger.info(f"‚úÖ File count: Total={total_records}, Original={original_records}")
            
            # Verificaci√≥n matem√°tica
            if total_records % duplicate_count != 0:
                logger.warning(f"‚ö†Ô∏è Total {total_records} not perfectly divisible by {duplicate_count}")
            
            return original_records, total_records
            
        except Exception as e:
            logger.error(f"‚ùå File counting failed: {e}")
            raise Exception(f"Cannot count from files: {e}")
    
    # ‚úÖ M√âTODO DE COMPATIBILIDAD
    def duplicate_mdd_real_fallback(self, mdd_path, ddf_path, duplicate_count, 
                                   workspace_path, original_filename):
        """M√©todo s√≠ncrono para compatibilidad"""
        import asyncio
        
        try:
            try:
                loop = asyncio.get_event_loop()
                if loop.is_closed():
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
            except RuntimeError:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
            
            result = loop.run_until_complete(
                self.process_duplicate_mdd_real(
                    mdd_path, ddf_path, duplicate_count, 
                    workspace_path, original_filename
                )
            )
            
            return result
            
        except Exception as e:
            return {
                "success": False,
                "error": f"Original method replication failed: {str(e)}",
                "mode": "ORIGINAL_METHOD_ERROR"
            }
    
    def _validate_mdd_ddf_files(self, mdd_path: str, ddf_path: str) -> Dict[str, Any]:
        """Validaci√≥n de archivos"""
        if not os.path.exists(mdd_path):
            return {"valid": False, "error": f"MDD not found: {mdd_path}"}
        
        if not os.path.exists(ddf_path):
            return {"valid": False, "error": f"DDF not found: {ddf_path}"}
        
        try:
            # Contar records del DDF original
            record_count = 0
            with open(ddf_path, 'r', encoding='utf-8', errors='ignore') as f:
                for line in f:
                    if line.strip():
                        record_count += 1
            
            return {
                "valid": True,
                "record_count": record_count,
                "mdd_size": os.path.getsize(mdd_path),
                "ddf_size": os.path.getsize(ddf_path)
            }
        except Exception as e:
            return {"valid": False, "error": f"Validation error: {str(e)}"}


# Funci√≥n standalone
def validate_mdd_ddf_files(mdd_path: str, ddf_path: str) -> Dict[str, Any]:
    service = IBMSPSSDataCollectionService()
    return service._validate_mdd_ddf_files(mdd_path, ddf_path)

# Instancia del servicio
mdd_real_service = IBMSPSSDataCollectionService()